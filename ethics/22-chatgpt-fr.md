# Le vrai danger avec #ChatGPT

3:03 "The technology is developing way too quickly for us to rely on legal instruments to fix this problem"
https://www.youtube.com/watch?v=Pm1Wgd9bbOk

Vous le savez certainement. 
Depuis quelques mois, un chatbot appelé #ChatGPT a été rendu accessible au grand public,
et sa spectacularité a conduit tous les grands médias a en parler,
certains parlant même de révolution ou de technologie de rupture,
souvent avec beaucoup d'enthousiasme.
Ceci étant, de nombreuses voix critiques se sont soulevées,
comme vous pouvez vous en rendre compte en lisant la page Wikipedia de #ChatGPT.  
https://fr.wikipedia.org/w/index.php?title=ChatGPT

Et si vous faites cet exercice, vous verrrez que parmi les critiques cités,
il y a un certain Lê Nguyên Hoang...

Pourtant, le plus grand danger de ChatGPT à mes yeux 
n'est pas listé dans cette page Wikipedia,
et il n'est quasiment jamais cité dans les médias,
à part ceux qui m'ont invité à parler de ce danger.

Et pour vraiment clarifier ce danger, je vais m'appuyer sur un chiffre :
6000 milliards de dollars.
6000 milliards de dollars.
6000 milliards de dollars, c'est d'après le Sénat français,
une estimation raisonnable du revenu annuel du cybercrime.  
https://www.senat.fr/presse/cp20211125d.html

C'est le double du PIB de la France,
et 4 fois plus que les revenus de Google (258G$), Amazon (470G$), 
Facebook (118G$), Apple (394G$) et Microsoft (198G$) combinés !

Or on peut estimer que ChatGPT a coûté quelques dizaines de millions,
peut-être quelques centaines de millions, pour être conçu,
notamment à cause de la facture électrique, 
des salaires des ingénieurs et 
de la collecte éthiquement douteuse des données pour "éduquer" ChatGPT,
comme j'en ai parlé chez Monsieur Phi.

Mais surtout, vu ce qu'OpenAI a partagé,
ChatGPT ne semble pas s'appuyer sur des techniques novatrices.
En fait, il existe toute une jungle d'algorithmes de langage similaires,
dont certains comme LaMDA et PALM de Google dont les prouesses sont sûrement comparables,
et dont d'autres sont Open Source comme Dumb Bloom de Hugging Face.  
https://huggingface.co/bigscience/bloom

Pire encore, la surmédiatisation des prouesses de ChatGPT a déjà amplifié
les investissements déjà massifs dans le développement de ces technologies,
ce qui va certainement conduire à des algorithmes bien plus spectaculaires encore que ChatGPT
dans les années, voire dans les mois qui viennent.
https://www.heidi.news/cyber/derriere-chatgpt-les-investissements-se-multiplient-pour-les-ia-generatives

Or, les moyens actuels, légaux, financiers et humains, 
pour auditer et réguler ces technologies sont extrêmement déficients,
et les lobbys industriels s'appuient sur le succès de ChatGPT et la course à la performance
pour dénigrer les appels à la régulation.  
https://twitter.com/le_science4all/status/1615067462373965840

Qui plus est, ce que ChatGPT a montré à toute l'industrie du cybercrime,
c'est à quel point ces algorithmes de langage pouvaient booster leur business,
en automatisant l'écriture de logiciels malveillants,
les attaques par phishing, les arnaques en ligne,
la désinformation, le cyber-harcèlement et les appels à la haine,
entre autre.

Enfin, et surtout, ChatGPT est un dangereux #CoolWashing des intelligences artificiels,
et aide à nous distraire de ses applications les plus dangereuses,
que ce soit les claviers intelligents qui lisent tout ce que vous tapez sur vos téléphones,
la publicité ciblée qui exploite ces données et d'autres 
pour optimiser les appels à la surconsommation des entreprises privées,
ou la recommandation algorithmique de contenus,
qui, bien plus que Google Search ou ChatGPT, est devenue le portail principal 
à travers lequel les humains accèdent au web.

17:06 "help me and the cybersecurity community make life much more difficult for the cybercriminals"
https://www.youtube.com/watch?v=fSErHToV8IU


## Le paysage des modèles de langage

Pour bien comprendre à quel point ce serait une erreur
de penser ChatGPT de manière isolée,
il est important de prendre un peu de recul sur le développement de tels algorithmes.
En fait, depuis 2017 et un article de chercheurs de Google publiés à NeurIPS, qui est l'une des plus grande conférence sur le Machine learning,
les algorithmes de langage s'appuient sur une même architecture appelée le Transformer.
Depuis, ils n'ont cessé de progresser, à un rythme spectaculaire,
si bien que les performances de ChatGPT ne m'ont personnellement pas vraiment surpris.  
https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html

En effet, chaque année, en entraînant un algorithme 10 fois plus gros que le précédent,
et en l'alimentant avec 10 fois plus de données,
les équipes de recherche des groupes privés n'ont cessé de montrer
que les modèles ainsi créés gagnaient drastiquement en spectacularité.
Bref, personnellement je n'ai pas tout à fait l'impression que ChatGPT est une rupture,
et encore moins qu'il s'agit du dernier mot à ce sujet.
On est dans une phase de croissance exponentielle dans la complexification de ces algorithmes,
rendues notamment possible par l'optimisation des machines pour les calculs spécifiques
de l'architecture dite du Transformer.

En particulier, le facteur limitant aujourd'hui n'est plus 
une innovation algorithmique révolutionnaire, 
même s'il faut encore combiner plein de petites astuces ;
le facteur limitant, c'est surtout l'ingénierie des machines à calculer,
la collecte de données massives et surtout la facture d'électricité pour faire les calculs.
On estime ainsi que les meilleurs modèles de langage coûtent des millions de dollars
en électricité.
https://lambdalabs.com/blog/demystifying-gpt-3#1  
https://venturebeat.com/ai/openai-launches-an-api-to-commercialize-its-research/  

En tout cas, le modèle Bloom conçu par Hugging Face pour le projet "ouvert" BigScience
rapporte avoir dépensé 2 à 5 millions de dollars.  
https://huggingface.co/bigscience/bloom

Pour ChatGPT, ils ont peut-être mis les bouchées doubles, ou les bouchées x10,
auquel cas on pourrait peut-être parler de dizaines, voire de cent millions de dollars.
Mais probablement pas plus, vu qu'OpenAI n'avait reçu qu'un milliard de dollars de Microsoft.  
https://openai.com/blog/microsoft/

Bref. Ce que je veux surtout dire, c'est que la conception d'algorithmes de langage
est surtout devenue une histoire d'argent aujourd'hui.
En tout cas, si c'est une affaire d'expertise, Google paraît mieux placé qu'OpenAI,  
https://twitter.com/le_science4all/status/1614648350057414656
puisque ce sont beaucoup plus eux qui sont derrière les principales avancées dans le domaine,
à la fois avec l'architecture des Transformers, 
mais aussi avec les machines de calcul dédiées comme les Tensor Processing Unit, ou TPU,
ou encore avec des innovations plus récentes comme les Switch Transformers ou Pathways.  
https://www.jmlr.org/papers/volume23/21-0998/21-0998.pdf  
https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/

En fait, Google a développé des chatbots spectaculaires avant ChatGPT,
à savoir LaMDA et PaLM,
mais ils ont préféré ne pas les rendre accessibles au grand public,
probablement pour éviter tout retour de batton.
En fait, Google a surtout plus à perdre en terme d'images de marque de Microsoft et OpenAI,
et ça me semble surtout être pour cette raison qu'ils n'ont pas misé
sur une euphorie comme celle qu'OpenAI a provoqué­e.

Cependant, avec les nouveaux investissements massifs dans ces technologies,
et avec l'avènement de solutions Open Source comme BLOOM,
il faut surtout s'attendre à ce que, dans les années à venir,
accéder à des modèles de langage très puissants à un coût raisonnable
deviendra facile pour des acteurs malveillants,
qui pourront alors affiner ces modèles comme bon leur semble.

Dès lors, qu'importe que ChatGPT ait des mesures de sécurité ou non.
En provoquant une euphorie, ils ont surtout essentiellement garanti
l'apparition éminente de modèles de langage bon marchés, extrêmement puissants,
et facilement reprogrammables par le cybercrime,
pour que celui-ci continue à voler des milliers de milliards de dollars,
quitte à mettre des hôpitaux, des voitures ou des systèmes bancaires en danger.
Et les algorithmes à la ChatGPT pourraient être particulièrement dévastateurs,
notamment parce que les cybercriminels s'appuient avant tout sur le langage
pour piéger leurs victimes.

16:47 "Cybercriminals [...] play with emotions [...] 
More than 90% of cyberattacks are caused by human errors"
https://tournesol.app/entities/yt:4EyWrC41Oc4

10:42 "Le cyberhacker profite [...] qui se font avoir chaque année."
https://tournesol.app/entities/yt:tfwASYKlypI


## Qu'est-ce que le cybercrime ?

Le cybercrime, justement, parlons-en. 
Et pour commencer, qu'entend-on par "cybercrime" ?
En gros, on parle d'utiliser les outils du numériques pour commettre des infractions,
des délits, voire des crimes.
Et il y a malheureusement une grande diversité de telles pratiques.
Je vous en propose une petite classification,
qui est très loin d'être exhaustive (et qui s'appuie un peu sur Wikipedia).

Pour commencer, il y a les arnaques.
Typiquement, il y a le coup du fameux prince nigérian, 
qui demande une aide financière qui sera récompensée ultérieurement.
Mais ça, c'est un peu l'arnaque de l'an 2000.
Depuis des arnaques similaires mais beaucoup plus sophistiquées ont été développées,
comme par exemple les love scams qui consistent à séduire des célibataires en ligne,
souvent pendant des mois,
avant de demander de l'aide financière.  
https://tournesol.app/entities/yt:NLwqzgniqpA

Une attaque similaire, appelée au faux support téléphonique,
consiste à faire croire à sa victime que son ordinateur est compromis, 
et qu'il lui faut appeler un numéro pour le soigner.
Sauf que c'est justement au moment de l'appel que l'arnaque a vraiment lieu,
par exemple parce que l'attaquant demande alors à l'utilisateur de se connecter 
à son compte en banque en ligne en écrivant le mot de passe 
que l'attaquant pourra ainsi noter.
Et si vous voulez en savoir plus, 
je vous recommande vivement cette exxcellente enquête de Micode.  
https://tournesol.app/entities/yt:gbYdQOde6EU

Globalement, récupérer vos codes d'accès à des sites web est une énorme activité du cybercrime.
Et l'une des manières les plus efficaces pour y parvenir est l'attaque par phishing.
Celle-ci consiste à vous faire visiter une page qui ressemble comme deux gouttes d'eau
à la page d'enregistrement d'un site très connu, comme GMail ou Facebook.
Sauf que le mot de passe que vous rentrez sur cette page est envoyée non pas à Google ou Facebook,
mais est envoyée directement aux machines de l'attaquant.  
https://tournesol.app/entities/yt:Vz_P6HDaZlg

Et alors, quand il s'agit de votre compte personnel, c'est déjà très dangereux,
notamment parce que l'attaquant peut ensuite se faire passer pour vous
pour demander de l'aide financière à vos proches.
Mais quand il s'agit de votre compte professionnel, ceci peut mettre votre entreprise en danger,
surtout si vous travaillez pour une entreprise de petite taille.  
https://www.crowdstrike.fr/ressources/livres-blancs/les-realites-du-ransomware-pour-les-petites-et-moyennes-entreprises/

En particulier, l'une des attaques qui se normalise de plus en plus sur les entreprises,
c'est d'exploiter de tels accès au système d'information de l'entreprise pour le paralyser,
en chiffrant par exemple toutes les données utiles au fonctionnement de l'entreprise,
comme les informations des clients nécessaires pour leur envoyer des factures.
Les attaquants vont ensuite typiquement demander une rançon pour rétablir le système d'information.
On parle alors d'attaque par ransomware.
Et comme en parle ici John Oliver, des milliers d'hôpitaux ont déjà été hackées ainsi,
et ont parfois dû refuser des patients en état critique.    
https://tournesol.app/entities/yt:WqD-ATqw3js

De façon terrifiante, les attaques de ransomware se démocratisent,
si bien qu'un marché de "ransomware-as-a-service" a émergé,
où n'importe qui peut payer pour lancer sa propre attaque.    
https://tournesol.app/entities/yt:WqD-ATqw3js

Sauf que dans un contexte de guerre entre superpuissance,
à l'instar de la Russie qui a cherché à paralyser le système électrique ukrainien,
les intérêts à paralyser des industries critiques d'ennemis vont bien au-delà du simple profit financier.
Dès lors, il faut craindre une cyberguerre catastrophique,
voire, notamment si les outils nécessaires pour effectuer une attaque à grande échelle 
deviennent abordables à un très grand nombre de groupes,
il faudrait potentiellement craindre plus encore les risques de cyberterrorisme.  
https://api.tournesol.app/entities/yt:yfr0BVCMAZA

Mais une grosse partie du cybercrime est beaucoup plus vicieux et discret.
En particulier les fraudes dites de publicité, d'identité et d'attribution consistent
à typiquement concevoir, voler ou racheter un grand nombre de faux comptes,
pour ensuite produire une quantité massive de désinformation,
pour faire gonfler la popularité, les prix ou les cours de certains produits,
pour amplifier le taux de clics, et donc de recommandations, de certains contenus,
ou pour signaler massivement certains contenus critiques,
au profit de gouvernements, de partis politiques ou d'entreprises privées.  
https://tournesol.app/entities/yt:V-1RhQ1uuQ4

Ces comptes, aujourd'hui souvent contrôlés par des fermes de trolls,
aussi appelées usines à clics,
sont aussi utilisés pour produire des shitstorms et harceler massivement certaines cibles.
Ce même harcèlement peut aussi abuser de deep fakes pour nuire à l'image de ces cibles,
voire à leur bien-être mental,
notamment en créant des deep fakes pornographiques.  
https://www.huffingtonpost.co.uk/entry/deepfake-porn_uk_5bf2c126e4b0f32bd58ba316

Love scam, faux support téléphonique, phishing, ransomware, cyberguerre, 
cyberterrorisme, fermes de clics, vagues de harcèlement, 
voire désinformation et appels à la haine.
Cette liste de cybercrime est loin d'être exhaustive, mais elle est déjà terrifiante.
Et surtout, très clairement, des algorithmes de langage comme ChatGPT vont énormément faciliter
la tâche de ceux qui veulent profiter de ces attaques illégales,
et rendre beaucoup plus difficile celle des professionnels de la cybersécurité.  
https://www.theregister.com/2023/01/18/russia_openai_chatgpt_workarounds/

Normaliser le #CoolWashing de ChatGPT sans parler avec insister 
des dangers civilisationnels de la démocratisation des algorithmes de langage,
et des besoins urgents de moyens monumentaux pour protéger les sociétés contre le cybercrime,
c'est rendre toute la population plus vulnérable encore à des disruptions majeures
des nombreux systèmes critiques dont nos sociétés dépendent tellement,
qu'il s'agisse des hôpitaux, du réseau électrique, du système bancaire,
ou du tissu de petites et moyennes entreprises.

4:11 "48% of us work for small businesses [...] this is bad news, guys."
https://tournesol.app/entities/yt:c_2Ja-OTmGc


## Le marché du cybercrime

OK. Le cybercrime peut être très dangereux. 
Mais à quel point son marché est-il grand ?
Faut-il vraiment croire que les avancées en IA seront plus souvent exploitées
par des acteurs malveillants que pour des fins nobles 
comme les applications médicales ?

Non seulement l'ampleur de ce marché est une énorme #MuteNews,
mais ce qu'on mesure sans doute tout aussi mal, 
c'est sa croissance spectaculaire.
Estimé à un coût total de 3000 milliards de dollars en 2015 par Cybersecurity Ventures,
il semble avoir atteint 6000 milliards en 2021,
et pourrait atteindre 10 000 milliards en 2025.  
https://www.youtube.com/watch?v=P6x4GhjDVHY  
https://cybersecurityventures.com/annual-cybercrime-report-2019/

À titre de comparaison, d'après mes recherches que j'avoue être un peu sommaire, 
et donc auxquelles si je suis loin de leur assigner une grande crédence,
le marché illégal des armes ne représenterait "que" 60 milliards de dollars par an.  
https://www.rankred.com/10-biggest-illegal-businesses-around-the-world/
Le marché des drogues illégales, lui, 
est estimé à 500 milliards de dollars par an selon certaines sources,  
https://www.talkingdrugs.org/report-global-illegal-drug-trade-valued-at-around-half-a-trillion-dollars
alors que le marché de la contrefaçon dépasserait mille milliards de dollars.  
https://www.rankred.com/10-biggest-illegal-businesses-around-the-world/

Tout ça pour dire que les individus louches prêts à enfreindre la loi pour s'enrichir
ont en fait tout intérêt à investir davantage dans le cybercrime
que dans ces autres marchés illégaux devenus trop classiques.
Et visiblement, ils sont énormément à s'y être mis.

Oui car, pour être clair, vu l'échelle des enjeux et des profits potentiels, 
le cybercrime est loin d'être une affaire de gamins isolés
sur leurs machines dans le garage de leurs parents.
Il s'agit aujourd'hui d'un véritable business, avec des fournisseurs et des clients.
Par exemple, en 2012, et selon Wikipedia, la menace prédominante du web
était non pas un virus, mais un kit que les clients pouvaient acheter 
pour eux-mêmes attaquer leurs victimes.
https://en.wikipedia.org/wiki/Blackhole_exploit_kit

En tout cas, dès 2015, Gini Rometty, alors PDG d'IBM, affirmait que, je cite,
"le cybercrime est la plus grande menace pour toutes les professions,
toutes les industries et toutes les entreprises du monde".  
https://www.csoonline.com/article/3210912/is-cybercrime-the-greatest-threat-to-every-company-in-the-world.html

En 2017, un expert en cybersécurité sondait son audience sur Twitter
pour voir si elle était d'accord avec ce constat.
La majorité approuvait ce message de Rometty.  
https://twitter.com/CybersecuritySF/status/888805918799998976

Imaginez si les voitures, le réseau électrique, les hôpitaux ou le système bancaire,
mais aussi plus simplement les systèmes de réservation de la SNCF,
ou encore les bases de données gouvernementales,
étaient tout à coup paralysés par des acteurs malveillants,
qui exigeraient des rançons énormes pour établir le fonctionnement de ces systèmes,
ou si des milliards de deepfakes demandaient à vos concitoyens d'effectuer une action obscure sur le web,
en se faisant passer pour leurs proches, pour leurs collègues, voire pour leurs boss.

20:45 "Please don't believe [...] you need to verify."
https://tournesol.app/entities/yt:BQ_JrFgUTKI

## Que faire ?

Face à ce discours réalistes du paysage des algorithmes vraiment déployés, 
les enthousiastes de l'IA se précipitent souvent pour minimiser la responsabilité des algorithmes.
Beaucoup vont ainsi comparer ces algorithmes à des couteaux.
Oui, les algorithmes peuvent être utilisés pour tuer.
Mais faut-il les interdire pour autant ? 
Lors d'un meurtre au couteau, la faute ne revient-elle pas à l'humain qui manipule ce couteau ?

Ce dont j'ai essayé de vous convaincre ici,
c'est que la comparaison entre ChatGPT et un couteau est maladroite,
surtout d'un point de vue conséquentialiste.
En particulier, les conséquences probables du développement d'un couteau,
surtout dans une société ou les couteaux sont déjà très largement répandus
et sont beaucoup plus probablement utilisés pour cuisiner et manger,
ne semblent absolument pas comparables aux conséquences probables du développement de ChatGPT,
qui normalise et démocratise des outils qui seront beaucoup plus probablement utilisés
par le cybercrime qu'à des fins utiles au bien-être et à la sécurité du plus grand nombre.

Autrement dit, le problème du développement et déploiement précipité des IA me semble contextuel.
Dans le monde dans lequel on vit aujourd'hui, 
avec ses contraintes écologiques et économiques,
et surtout avec la prolifération incontrôlée du cybercrime 
et l'instabilité géopolitique à l'échelle mondiale,
accélérer le développement d'algorithmes surpuissants à tout faire 
me paraît très nettement beaucoup plus dangereux que 
freiner ce développement et investir massivement dans la régulation,
d'autant que les applications bénéfiques à l'humanité me semble très limitées et peu convaincantes.
Autrement dit, la balance risque-bénéfice me semble pencher très largement en faveur des risques.

Malheureusement, cette balance risque-bénéfice est souvent très loin de l'esprit de beaucoup.
Le #CoolWashing de l'IA, 
mais aussi l'insistance à parler de problèmes secondaires à mes yeux,
comme le rôle de "l'humain", l'empreinte carbone non-négligeable mais pas non plus délirante de l'IA,
ou le fait que ces technologies ne soient pas souvent conçues sur le territoire européen, 
tout ceci me semble avoir conduit à un grave manque de méfiance du grand public,
mais aussi des chercheurs, des journalistes et des politiciens.
Dans le contexte actuel où le cybercrime prédomine, ces algorithmes sont extrêmement dangereux,
et il faudrait urgemment investir beaucoup plus dans leur régulation et leur audit.
Et ça, ça nécessite non seulement des lois, 
mais ça requiert plus encore des investissements beaucoup plus importants 
dans des agences de cybersécurité comme l'Agence Nationale de la Sécurité des Systèmes d'Information,
et dans la recherche publique sur la cybersécurité,
qui, je pense, devrait prioriser le recrutement de chercheurs orientés sécurité
à celui d'experts en optimisation des systèmes d'apprentissage sans attention à la sécurité.

Après tout, le cybercrime n'est pas un problème individuel.
Si demain des employés de Google, de Tesla, d'EDF ou de la Société Générale se font hacker,
et si cela permet aux attaquants d'accéder et de paralyser des systèmes d'information critiques
de ces multinationales dont les produits sont utilisés partout le tissu économique et la population,
alors les conséquences seraient catastrophiques pour tous,
y compris pour moi, même si j'ai fait très attention à ma propre cybersécurité.
Une réponse collective est nécessaire, 
et les développeurs, chercheurs, journalistes, politiciens et juristes ont un rôle critique 
dans cette réponse aujourd'hui très clairement très déficiente.

Mais surtout, le plus gros danger de l'attention démesurée donnée à OpenAI,
ça me semble être surtout l'inattention que cela provoque pour les algorithmes les plus dangereux,
qui restent à mes yeux les algorithmes de ciblage publicitaire et de recommendation de contenus.
Ces algorithmes sont déjà très largement déployés, 
ont provoqués des chaos sociaux aux États-Unis, au Brésil et au Royaume-Uni,
et des génocides au Myanmar, en Éthiopie et peut-être bientôt en Inde.  
https://www.aljazeera.com/news/2022/1/16/expert-warns-of-possible-genocide-against-muslims-in-india

Ils me semblent très clairement violer beaucoup de lois,  
https://tournesol.app/entities/yt:sAjm3-IaRtI
mais la justice manque aujourd'hui de moyens et d'attention  
https://tournesol.app/entities/yt:1ml-OLDV7Vw
pour prioriser l'application, par exemple de la régulation sur les publicités,
pour punir la diffusion massive de contenus illégaux dont Google et d'autres profitent tant.
Et vu ce manque de moyens difficile à combler,
je trouverais cela judicieux d'imposer des lois simples à faire appliquer, comme #TaxonsLaPub.
https://tournesol.app/entities/yt:sGLiSLAlwrY

En particulier, de manière très concrète,
alors que des milliards de fonds philanthropiques ont été versés à des entreprises comme OpenAI,
des alternatives dédiées à l'éthique, la sécurité et la gouvernance collaborative
des algorithmes les plus dangereux du web comme Tournesol
manquent gravement de dons et de visibilité, au niveau de la recherche et des médias.
Dans le cas de Tournesol, après maintenant presque 3 ans,
on a juste de quoi payer un salaire de développeur ;
et même avec les meilleures idées qui soient, 
c'est compliqué de concurrencer OpenAI, Google ou TikTok avec 1 seul employé,
d'autant que le développement des algorithmes sécurisés dont on a besoin
est en fait plus sophistiqué, en tout cas mathématiquement, 
que celui de #ChatGPT, LaMDA ou du "bouton magique" de TikTok.  
https://tournesol.app/entities/yt:RMJz3nVE-78

Heureusement, au niveau de la recherche en tout cas, 
les problématiques d'éthique, de sécurité et de gouvernance gagnent en importance.
Mais vous pouvez nous aider à accélérer cette tendance,
en utilisant notre extension Tournesol pour Chrome et Firefox,
en contribuant pour identifier plus de vidéos de top qualité,
et surtout en promouvant la plateforme autour de vous et des journalistes.
C'est en encourageant ce genre d'initiatives que vous pourrez pousser les technologies
à être conçues avec davantage de considération pour la sécurité et le bien-être du plus grand nombre.

03:45 "I think that the next big technology should be the creation of a safer Internet".
https://www.youtube.com/watch?v=Pm1Wgd9bbOk

