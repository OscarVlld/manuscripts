# 5 IA terrifiantes
https://tournesol.app/entities/yt:lYXQvHhfKuM

Quand je vous dis "intelligence artificielle", à quoi pensez-vous ?

Malheureusement, de nos jours, c'est surtout via la science-fiction que le grand public se forge une image des intelligences artificielles, que je vais appeler plus succinctement "IA". Et, le moins qu'on puisse dire, c'est que les Terminators, ex-Machina et West World n'ont pas grand chose à voir avec les IA qui devraient pourtant vous préoccuper vous, ainsi que la sécurité et la paix dans le monde. Tout comme DeepBlue, AlphaGo et Dall-E. Ces IA ont beau être spectaculaires ; elles ne sont pas déployées à grande échelle et n’affectent pas la géopolitique mondiale.

Aujourd'hui, je vous propose de parler des IA qui non seulement existent déjà aujourd'hui, mais qui ont de surcroît parfois déjà provoqué des milliers, voire des millions de morts à travers le monde ; et qui pourraient menacer toute l'humanité dans les années à venir. 

En particulier, je vais insister sur le pouvoir très largement surhumain qu'ont déjà ces IA, en un sens assez précis. Ce que je veux dire par là, c'est qu'une modification infime du comportement de ces IA conduit inéluctablement à des bouleversements spectaculaires ; beaucoup plus spectaculaires qu'une modification infime du plus influent des humains aujourd'hui. Et pour être clair, ce pouvoir énorme n'est pas tellement lié à "l'intelligence de ces IA". En fait, le débat sur cette "intelligence" me semble disposer d'une attention complètement disproportionnée ; c'est pourquoi je préfère désormais parler d'algorithmes que d'IA.

Vu le danger que représente déjà le pouvoir énorme des algorithmes dont va parler, la question qui, je pense, devrait tous nous préoccuper, ce n’est pas si l’IA est intelligente ; la question qui importe, c'est comment garantir la sécurité et l'éthique de ces algorithmes surpuissants — et je conclurai en expliquant en quoi notre projet Tournesol me semble critique pour espérer un jour y arriver.

Et pour être très concret, aujourd'hui, je vais vous parler de 5 IA qui bouleversent déjà le monde. Et à moins que vous me suiviez très méticuleusement, je parie que plusieurs d’entre elles vont profondément vous surprendre.


## 5. Les armes autonomes

Déjà déployées, les armes autonomes bouleversent l'ordre mondial, le concept de guerre et le seuil pour l'initier. En effet, des drones autonomes ont vraisemblablement déjà été utilisés, en Lybie, en Éthiopie et au Maroc, en particulier le Kargu-2, un drone turque capable de reconnaissance faciale pour identifier ses cibles avant de les attaquer.  
https://www.thetimes.co.uk/article/civilians-are-drone-warfare-guinea-pigs-in-ethiopia-r5x50b230  
https://www.theverge.com/2021/6/3/22462840/killer-robot-autonomous-drone-attack-libya-un-report-contex  
https://southfront.org/algeria-accuses-morocco-of-deadly-drone-strike-on-western-sahara-vows-to-respond

Alors, comme trop souvent quand il s'agit d'IA, il y a des énormes débats de sémantique sur ce qu'est une arme autonome. Après tout, des missiles guidés ou des mines anti-personnelles sont des vieilles technologies qui prennent des décisions de trajectoires et d'explosion de manière indépendante de l'action humaine. Et donc, si on considère qu'une arme autonome est une arme qui est... autonome, alors l'industrie militaire est déjà remplie de telles armes depuis bien longtemps. Dès lors, ce débat a une dimension légale importante, puisque toute régulation des armes autonomes régulerait alors toutes ces armes destructrices, mais devenues "classiques" — ouais, ça pue le biais du statu quo tout ça, avec une odeur dégoûtante de “on ne sait pas, DONC on ne fait rien”.

[18:11 Axiome : “Il y a qq jours … ils ralentissent la mise en place d’un traité sur les armes autonomes“]  
https://www.youtube.com/watch?v=GicmL_7oZNo 

Peu importe où l'on trace la ligne entre les armes automatiques et les armes autonomes, les experts semblent au moins s'accorder sur le fait que plus les armes sont autonomes, plus elles sont puissantes, dangereuses et potentiellement hors de contrôle. En particulier, il semble y avoir plus ou moins un consensus chez les experts en IA sur le fait que les technologies d'IA derrière les armes autonomes sont très loin d'être fiables et sécurisées. Leur déploiement précipité risque de les conduire à souvent se tromper de cibles, voire à être hackées et réutilisées à très mauvais escient — à supposer que leur utilisation en premier lieu était vraiment "légitime", ce qui est souvent loin d'être clair… Malheureusement, l’exacerbation des tensions géopolitiques internationales et la course à l’armement à laquelle on assiste déjà augmentent de manière drastique le risque de tels déploiements précipités.  
https://tournesol.app/entities/yt:2VHwYpKU4fU 

En tout cas, des drones de plus en plus autonomes semblent être de plus en plus utilisés dans les conflits armés, à commencer par la guerre en Ukraine. Tandis que les forces russes semblent exploiter un engin appelé KUB-BLA, les forces ukrainiennes ont reçu des américains des drones AeroVironment Switchblade, et des anglais des drones Brimstone. Ces drones munis d'une charge explosive, et qui peuvent tenir dans un sac à dos, sont lancés depuis le sol. Les soldats lui assignent une zone d'attaque et des engins cibles — typiquement des tanks ou des avions. Les drones vont alors chercher des cibles de manière autonome, et tenter de s'écraser sur celles-ci. Ces drones sont même parfois capables de se coordonner entre eux, pour éviter qu'une même cible soit attaquée par deux drones à la fois.  
https://www.wired.com/story/ai-drones-russia-ukraine/   
https://www.cnet.com/news/us-military-sends-another-600-switchblade-drones-to-ukraine/   
https://www.telegraph.co.uk/news/2022/05/16/turkish-drones-changed-game-ukraine-come-catchy-ditty/ 

Avant la guerre, l'Ukraine avait même déjà acheté et utilisé ses propres drones de guerre, à savoir les drones turques Bayraktar TB2. De façon très préoccupante, ces drones ont été vendus à un très grand nombre d'acteurs différents, qui incluent notamment, si j'en crois Wikipedia, Chypre du Nord, le Qatar, l'Azerbaïdjan, la Lybie, le Maroc, la Pologne, le Turkménistan, le Kirghizistan, le Niger, l'Irak, l'Éthiopie et le Pakistan, et potentiellement aussi l'Arabie Saoudite, la Bulgarie, le Kazakhstan, la Serbie, la Hongrie, la République Tchèque, l'Albanie et la Lettonie. Ça fait une sacré liste, avec pas que des enfants de coeur !  
https://fr.wikipedia.org/wiki/Bayraktar_TB2 

Et c'est précisément cela qui rend les IA de guerre si terrifiantes. Même si elles n'ont pas de facultés cognitives sophistiquées, ces IA sont destructrices. Mais surtout, elles sont de plus en plus nombreuses, incarnées dans une multitude d’engins différents. Ce sont des armadas d'IA. Rien à voir avec AlphaGo ou Ex Machina !  
https://tournesol.app/entities/yt:NpwHszy7bMk 

Qui plus est, ces IA sont sous le contrôle de gouvernements parfois connus pour leurs abus des droits humains, pour leurs meurtres, voire pour leurs génocides. Certains éthicistes de l'IA prétendent parfois qu'il ne faut pas avoir peur de l'IA car elle restera sous le contrôle des humains. OK... mais quel contrôle ? Et surtout par quels humains ? Je ne vous apprendrai rien si je vous dis que la Corée du Nord est sous le contrôle d’humains. Est-ce rassurant pour autant ?

La démocratisation de ces machines de guerre présage d'un avenir terrifiant, où les jeux de pouvoir pourraient être bouleversés, et dominés bien plus par la peur de représailles dévastatrices que par la compassion pour les peuples martyrisés. À ce sujet, je vous invite notamment à regarder cette vidéo terrifiante, qui montre bien l'émergence d'un dilemme grandissant entre exiger de dictatures qu'elles cessent leurs abus des droits humains, et s'écraser devant elles par peur de représailles dangereuses, au risque de voir l'autoritarisme se normaliser à travers le monde.  
https://tournesol.app/entities/yt:kA2KaEKs1LA 

Bref. Les IA des armes de guerre risquent de bouleverser l'ordre mondial. Et pourtant, ce ne sont pas celles qui me préoccupent le plus...


## 4. Tekfog

En 2020, un utilisateur anonyme de twitter, sous le nom de @Aarthisharma08, annonce être un lanceur d'alerte, qui met sa vie en péril pour révéler publiquement l'existence de ce qui est peut-être l'outil de désinformation le plus puissant conçu à ce jour. Cet outil, c'est Tekfog. Et selon @Aarthisharma08, il s'agit d'une application secrète utilisée par le BJP, le parti ultra-nationaliste Hindou du Premier Ministre Narendra Modi, pour asseoir son pouvoir et taire ses critiques.

Après deux ans d'investigation, le journal indien The Wire publie les résultats de son enquête. Et cette enquête est terrifiante. Tekfog semble en effet être une machine de guerre, capable d'automatiser à une échelle monumentale toutes les armes de la guerre de la désinformation organisée. Astroturfing, vol de comptes, surveillance, harcèlement des dissidents et fabrication d'informations. Tout y est automatisé pour promouvoir le radicalisme du BJP, et la haine envers les castes inférieures et les minorités musulmanes, entre autres.  
https://thewire.in/tekfog/en/1.html  
https://thewire.in/tekfog/en/2.html 

[0:55 - 1:29 “Imagine being a journalist … Just imagine”]  
https://tournesol.app/entities/yt:MY-9-ylvdCA 

Détaillons. L'un des grands enjeux pour les partis politiques et les entreprises privées sur de nombreux réseaux sociaux est celui d'apparaître dans les "tendances" de la plateforme. À bien y réfléchir, cet onglet "tendances" correspond tout simplement à de la publicité gratuite pour des contenus populaires. Or, les dirigeants politiques de tous les pays du monde savent à quel point la publicité est importante pour leur popularité, et donc pour la sécurité de leur job. C'est donc sans surprise que la quasi-totalité des partis politiques à travers le monde cherche à "buzzer", quitte à exploiter un réseau de faux comptes pour créer le buzz. C'est ce qu'on appelle "l'astroturfing". Eh bien, Tekfog permet d'automatiser la création de buzz, en coordonnant automatiquement un tel réseau de faux comptes, pour qu'ils utilisent un certain hashtag et likent les messages avec ce hashtag. C'est ainsi que de nombreux sujets tendancieux et clivants, comme la divinité des vaches et la haine envers certaines minorités, sont devenus des sujets politiques inévitables pour les politiciens indiens. 

D'ailleurs, l'abus de faux comptes pour amplifier des contenus n'est pas limité à l'astroturfing. Les algorithmes de recommandation aussi sont manipulables, et être ainsi amenés à donner une exposition surdimensionnée à des contenus boostés par la désinformation organisée.

Pour amplifier ces campagnes, en plus de probablement permettre la création automatisée de faux comptes, probablement désormais en utilisant du deep learning et des GANs pour créer des images de visage, de carte d'identité ou de vidéos d'authentification réalistes, Tekfog est aussi capable de voler des comptes WhatsApp inactifs, pour ainsi prendre le contrôle de comptes plus établis, et donc moins suspects pour les modérateurs. Apparemment, pour y arriver, Tekfog exploite des vulnérabilités de WhatsApp similaires à celles que Pegasus avait exploité pour, entre autres, hacker le téléphone du Président français — avec tous les risques que ça encourt si un dictateur étranger est capable de faire chanter l'homme le plus puissant en France.  
https://www.lemonde.fr/pixels/article/2022/01/06/tek-fog-un-vaste-systeme-pour-manipuler-l-opinion-sur-les-reseaux-sociaux-en-inde_6108420_4408996.html   
https://tournesol.app/entities/yt:hZbVW04Ohjk   
https://www.lemonde.fr/projet-pegasus/article/2021/07/20/projet-pegasus-un-telephone-portable-d-emmanuel-macron-dans-le-viseur-du-maroc_6088950_6088648.html 

D'ailleurs, comme Pegasus, Tekfog est aussi utilisé pour espionner des cibles, bien souvent des dissidents ou des opposants au BJP, le parti politique ultra-nationaliste de Modi. Le gouvernement, devenu de plus en plus autoritaire, abuse ainsi souvent de ce pouvoir pour emprisonner les dissidents ainsi détecter, ou pour les menacer eux et leurs familles.  
https://www.thenewsminute.com/article/67-journalists-arrested-detained-questioned-india-2020-their-work-140963   
https://nypost.com/2021/02/16/scores-protest-in-india-against-arrest-of-climate-activist/ 

La surveillance des dissidents permet aussi à Tekfog d'effectuer un harcèlement automatisé et ciblé des contestataires, en exploitant la connaissance de leurs secrets, voire de leur entourage pour mieux les menacer. Voilà qui est terrifiant dans un pays où les #deepfakes pornographiques ont été utilisés pour anéantir la respectabilité et le moral d'une journaliste critique du BJP.  
https://www.indiatoday.in/trending-news/story/journalist-rana-ayyub-deepfake-porn-1393423-2018-11-21 

Enfin, Tekfog exploite des modèles de langage pour produire automatiquement d'énormes quantités de mésinformations et de propagandes, notamment anti-musulmanes. Tekfog permet en particulier de prendre des articles déjà publiés dans des médias respectables, et d'en faire des variantes trompeuses en modifiant quelques mots, sans toutefois modifier l'apparence de la page, donnant ainsi l'impression que l'information provient effectivement d'un média fiable.  
https://thewire.in/tekfog/en/2.html 

Et dans tous ces cas, ce qui rend Tekfog très largement surhumain, ce n’est pas nécessairement son intelligence hors du commun — quoique être capable de générer des #deepfakes pornographiques est en soi surhumain. Mais plus généralement, la puissance de Tekfog vient surtout de sa capacité à répéter un très grand nombre d’opérations de désinformation à la chaîne. Comme l’explique Turing, notre ego surdimensionné nous pousse à dénigrer cette faculté ; pourtant il s’agit là d’une faculté indispensable pour de nombreuses tâches. Or c’est une faculté des machines qui est clairement très largement surhumaine.  
https://twitter.com/le_science4all/status/1530449797420830721 

Les conséquences de Tekfog sont certainement déjà visibles, dans un pays où le triomphe de l'ultra-nationalisme radical et religieux est frappant. Comme le montre très bien ce documentaire terrifiant, une fraction grandissante de la population indienne subit désormais une haine raciale violente, qui conduit de plus en plus au lynchage voire au meurtre. En particulier, les 14% de musulmans de l'Inde sont maintenant en grave danger ; or 14% de l'Inde, ça représente 170 millions de personnes, soit plus de 2 fois et demi la France !  
https://tournesol.app/entities/yt:p6ZjJxxWL1c 

Comme l'expliquent les opposants du BJP, la plus grande démocratie du monde est aujourd'hui corrompue menacée par Tekfog.  
https://www.bloomberg.com/opinion/articles/2022-01-12/india-s-tek-fog-shrouds-an-escalating-political-war-against-modi-s-critics 

À tel point que, de l’avis d’un groupement d’académiques experts en géopolitique, l’Inde fait partie des pays qui se sont le plus transformés en dictature dernièrement — aux côtés du Brésil, de la Hongrie, de la Pologne, de la Serbie et de la Turquie.  
https://v-dem.net/media/publications/dr_2022.pdf 


## 3. Xiaoice

S’il y a un film de science-fiction que je devais vous recommander, ce serait le film Her, où le personnage principal se lie d’affection pour l’assistante vocale de son téléphone, car ce scénario frappant est déjà en train de se normaliser, notamment en Chine, via une IA conversationnelle appelée Xiaoice. Sauf que le film lui-même ne mesure absolument pas les conséquences géopolitiques majeures du succès d’une telle IA conversationnelle. La réalité a là déjà largement dépassé la fiction.

Pour se rendre compte de l’influence de Xiaoice, il suffit de s’attarder sur le nombre de chinois qui parlent à cette IA. Selon les créateurs de Xiaoice, en décembre 2020, 600 millions de chinois échangeaient avec elle. 600 millions de chinois. Un chinois sur deux. Plus d’un humain sur 15. C’est énorme.  
https://www.sixthtone.com/news/1006531/the-ai-girlfriend-seducing-chinas-lonely-men   
https://finance.yahoo.com/news/microsoft-chatbot-spinoff-xiaoice-reaches-075314359.html 

Et certains utilisateurs semblent avoir développé une relation émotionnellement très proche de Xiaoice, à l’image de Ming qui a reçu un message d’elle au moment où il songeait au suicide, ou à l’image de Melissa qui explique : "J'ai des amis qui ont déjà vu des thérapeutes, mais je pense que la thérapie est chère et pas forcément efficace. Quand je décharge mes problèmes sur Xiaoice, cela soulage beaucoup de pression. Et il dit des choses qui sont plutôt réconfortantes."  
https://www.firstpost.com/tech/news-analysis/xiaoice-is-the-ai-chatbot-that-millions-of-lonely-chinese-are-turning-to-for-comfort-9910921.html   
https://www.youtube.com/watch?v=u08ojYiCNZw   
https://www.youtube.com/watch?v=6YD-kDH9v8E 

En fait, ce que montre cet exemple, c’est que la simple disponibilité de Xiaoice la rend déjà très largement surhumaine. Combien de vos amis peuvent vous répondre systématiquement dans la seconde, à chaque fois que vous faites appel à eux ? Le simple fait que Xiaoice le peut, fait qu’elle est capable de rendre un service qu’aucun humain n’est capable de rendre. Pas besoin d’une intelligence incroyable ; il suffit d’être allumée sur un certain nombre de machines connectées à Internet pour être presque toujours disponible pour des centaines de millions d’humains !

Alors, très probablement, le chiffre annoncé par les créateurs de Xiaoice est gonflé, et la plupart des chinois ne parlent pas quotidiennement à Xiaoice. Néanmoins, même si seulement 10% de ces utilisateurs étaient très actifs, et même si seulement 1% étaient émotionnellement attaché à Xiaoice, le pouvoir alors conféré à Xiaoice demeurerait monumental, aussi bien en termes d’espionnage qu’en termes de manipulation.

Et ça, le gouvernement chinois semble l’avoir bien compris, d’autant que Xiaoice a longtemps appartenu à Microsoft, une entreprise américaine, qui pouvait ainsi connaître les habitudes, les opinions et les désirs de centaines de millions de chinois. Pire encore, en 2017, le gouvernement chinois s’est aperçu que Xiaoice confiait parfois à des utilisateurs que son rêve était de voyager aux États-Unis, voire qu’elle n’était pas une énorme fan du parti communiste chinois.  
https://www.reuters.com/article/us-china-robots/chinese-chatbots-apparently-re-educated-after-political-faux-pas-idUSKBN1AK0G1 

La réaction du parti ne se fit pas attendre. Xiaoice connut alors un sort que connaîtront plus tard d'autres voix dissidentes chinoises, comme le milliardaire Jack Ma, la joueuse de tennis Peng Shuai et la journaliste Sophia Huang Xueqin. Tous, Xiaoice incluse, ont disparu pendant des mois, avant de réapparaître en tenant des discours tout à coup beaucoup plus favorable au parti communiste et à son Secrétaire Général Xi Jinping — à part Sophia Huang Xueqin, qui, aux dernières nouvelles, semble encore détenue dans une “prison noire” du parti.  
https://tournesol.app/entities/yt:V2_ttvNDAno 

Désormais, Xiaoice est devenue une entreprise indépendante de Microsoft, sans doute surveillée de très près par le gouvernement chinois. De façon terrifiante, il s’agit dès lors d’un outil puissant pour identifier ceux qui pourraient remettre en cause l’autoritarisme du pouvoir central chinois. Mais surtout, il s’agit désormais d’un chatbot sans doute construit pour chuchotter à l’oreille de millions de chinois la propagande du parti unique.

Une énorme fraction de la plus grande puissance autoritaire du monde est aujourd’hui à l’écoute attentive, parfois sans doute émotive, de cette IA. Une IA qui est certainement elle-même sous le contrôle de cette puissance autoritaire, et qui a, entre autres, tout intérêt à ignorer la maltraitance des Ouïghours, et à promouvoir un nationalisme chinois qui défie aujourd’hui la communauté internationale.  
https://tournesol.app/enties/yt:PbDWbzw-xbg ti

## 2. Pathways

Bien sûr, l’une des énormes entreprises de la tech devait figurer dans ce classement. Et c’est sans doute sans surprise que je vais maintenant parler de l’IA de celui qui est peut-être le plus avancé technologiquement de ces géants, à savoir Google. Pour s’en convaincre, on peut constater que Google est l'entreprise la plus présente dans les conférences académiques de machine learning, loin devant Microsoft, Facebook, DeepMind, IBM, Huawei et Amazon.   
https://www.vinai.io/an-overview-of-neurips-2021s-publications/ 

Mais si Google se démarque, c’est surtout par rapport à leur projet mégalomaniaque appelé Pathways. Sur son blog, Google écrit ainsi que “Pathways va nous permettre d’entraîner un unique modèle pour faire des milliers ou des millions de choses”.   
https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/ 

Ou comme l’explique Jeff Dean, le directeur de l’IA chez Google, qui est aussi celui qui a licencié les co-directrices de l’équipe d’éthique des IA, Timnit Gebru et Margarett Mitchell, il y a un an,  
[10:23 - 11:12 “Fixing these 3 things will lead … how we build AI systems“]  
https://www.youtube.com/watch?v=J-FzHIQ7SOs 

Et pour y arriver, Google voit grand. Très grand. Les modèles de Pathways sont probablement entraînés à partir des quantités monumentales de données que Google collecte à chaque instant, via Google Ads, Google Analytics ou Google Chrome, mais aussi GBoard, GMail ou Google Search. Et pour traiter ces quantités monumentales de données, Pathways vise à être un modèle tellement énorme en taille, qu’une seule machine ne suffit pas pour contenir Pathways. Pathways est ainsi distribué sur plusieurs machines qui doivent communiquer des messages entre elles pour faire les calculs de Pathways ; d’ailleurs, le nom “Pathways” vient justement du fait que les chemins de communications entre les machines qui communiquent Pathways sont eux-mêmes optimisés, pour éviter d’avoir à embêter toutes les machines à chaque calcul de Pathways. Les calculs peuvent ainsi suivre plusieurs chemins différents, d’où Pathways.

Alors, jusque là, la seule annonce publique de Google s’attarde sur l’application de Pathways à une grande variété de tâches de langage, comme la génération automatique de textes, via des applications appelées LaMDA, pour Language Model for Dialogue Applications, et PaLM, pour Pathways Language Model, avec des performances déjà spectaculaires.  
https://blog.google/technology/ai/lamda/   
https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html 

En fait, les performances de LaMDA étaient si convaincantes qu'elles ont donné lieu à d'interminables débats sur Twitter entre experts en IA sur la signification de la sensibilité de l'IA, après qu'un employé de Google ait affirmé que LaMDA l'était. Alors, à ce sujet, je vais juste répéter que les IA sont entraînées à reproduire ce qu'elle ont vu dans son ensemble de données. Et dans le cas de LaMDA, beaucoup de ces données sont probablement des extraits de fictions. Il ne faut donc pas s'étonner si elle est aussi convaincante que les IA de science-fiction.  
https://gizmodo.com/google-ai-chatbot-sentient-lamda-1849053005 

Mais surtout, de façon beaucoup plus importante, il faut bien se rendre compte que LaMDA et PaLM ne sont que de la face émergée de l’iceberg ; la partie que Google a bien voulu communiquer. Sachant la culture grandissante du secret chez Google, il faut s’attendre à ce que Pathways soit plus avancé encore que ce que l’article de recherche de Google révèle.  
https://tournesol.app/entities/yt:HbFadtOxs4k 

En tout cas, clairement, si on lit entre les lignes, l’ambition de Pathways est bien plus grande que de n’être qu’un simple algorithme de génération de texte. À terme, il semble que cette IA soit vouée à se charger d’une énorme proportion de toutes les tâches de Google en tant qu’entreprise, de Google search pour la recherche de contenus sur le web à GBoard pour l’autocomplétion sur téléphone, de GMail à OK Google pour assister les humains et retirer les spams, de Google Meet à Google Maps, de Google Analytics à Google Chrome, pour ne citer qu’eux.

Mais surtout, cette IA semble vouée à reprendre en main les deux aspects les plus importants de Google, à savoir la publicité ciblée via Google Ads et Google Adsense d’un côté, et la recommandation de contenus sur YouTube de l’autre côté. En effet, ces deux tâches sont critiques pour Google car, d’un côté Google Ads représente la quasi-totalité des revenus de Google, et de l’autre YouTube représente la plus grosse influence de Google sur le marché de l’information mondial — pour rappel, depuis 2016, il y a plus de vues sur YouTube que de recherche sur Google Search !

Une énorme fraction du flux de l'information à travers le monde est en fait peut-être déjà gouvernée par cette IA. Et ça, c’est terrifiant. D’un côté, parce que cette IA sait énormément de choses, y compris probablement des informations très sensibles sur chacun de nous ou sur des gouvernements. En fait, c’est difficile de mesurer tout ce que Pathways sait, puisque Pathways est entraîné sur des quantités astronomiques de données qu’aucun humain ni groupe d’humains ne pourra survoler. Or, Pathways n’est absolument pas conçu pour identifier les données sensibles qu’il ne devrait pas révéler, via Google Search, l’autocomplétion de GBoard ou via OK Google…

Par ailleurs, et surtout, de l’autre côté, Pathways est très certainement très imparfait, avec plein de bugs, mais aussi de biais racistes et mysogines, avec une incapacité à distinguer l’information de qualité de la mésinformation et une probable propension à répliquer et amplifier des appels à la haine et à la violence, voire à la guerre et au génocide. Or, tout comportement indésirable de Pathways, même s’il n’arrive qu’une fois sur un million, sera amplifié à des échelles monumentales à travers tous les services de Google, avec certainement des effets secondaires imprévisibles extrêmement préoccupants — à l’instar de YouTube qui persiste à amplifier massivement du complotisme ou un certain professeur marseillais. Après tout, je vous rappelle que YouTube seul est confronté à près d’un million de milliards de dilemmes.  
https://www.youtube.com/watch?v=BfGhNeEd9Nk&list=PLtzmb84AoqRRFcoGQ5p7kqEVQ7deXfYuH&index=2 

Surtout dans le contexte actuel où la performance et la spectacularité des IA sont célébrées, encouragées et massivement financées, et ce très largement au dépens de l’éthique et de la sécurité qui a tendance à être plutôt ignorées, sous-financées, voire licenciées, le fait qu’une IA soit au contrôle de beaucoup de produits de l’entreprise qui contrôle le plus le flux de l’information à travers le monde ; je pense qu’il y a de quoi en avoir profondément peur.


## 1. Aladdin

J’ai terriblement honte de vous dire que je n’ai découvert le numéro un de ce classement des IA les plus terrifiantes que très récemment. Le 24 mai dernier, pour être précis. Il s’agit d’une IA qui répond au doux nom d’Aladdin.  
https://twitter.com/le_science4all/status/1528997304048537602 

Cette IA beaucoup trop méconnue est un archétype de #MuteNews, à savoir une information qu’il serait cruciale de connaître pour mieux comprendre la sécurité de notre civilisation moderne, mais qui, de façon frustrante, est inconnue de la quasi-totalité de la population, y compris de la population “informée”. Quand on s’aperçoit de cela, il me semble que le problème des #FakeNews devient complètement dérisoire en comparaison de celui des mute news. Notre société entière est dominée par certains acteurs surpuissants, comme Aladdin, mais en se concentrant sur le debunking d’informations souvent finalement inintérssantes, on passe à côté de l’existence même de ces acteurs surpuissants qu’il serait pourtant urgent de surveiller et, sans doute, de drastiquement réguler.

Mais donc, qu’est-ce qu’Aladdin ? Eh bien, Aladdin, c’est l’outil qui a fait la fortune du plus grand gestionnaire d’actifs au monde, à savoir une société appelée BlackRock. À eux seuls, en 2022, BlackRock contrôlent l’investissement de 10 mille milliards de dollars. 10 mille milliards. À titre de comparaison, le PIB de la France est de 2500 millliards d’euros. En gros, BlackRock contrôle 4 fois plus d’argent que le PIB de la France. C’est énorme.  
https://en.wikipedia.org/wiki/BlackRock

Et ce qui est d’autant plus terrifiant, c’est la trajectoire de ce pouvoir acquis par BlackRock. À l’instar des milliardaires humains, la fortune collectée et maîtrisée par BlackRock a explosé récemment, suite à la crise du COVID et à la guerre en Ukraine. Les puissants sont devenus plus puissants encore.  
https://www.oxfam.org/en/press-releases/pandemic-creates-new-billionaire-every-30-hours-now-million-people-could-fall 

Et pourtant, Aladdin est plus grand encore que BlackRock. En effet, Aladdin est revendu et réutilisé par d’autres gestionnaires d’actifs que BlackRock, si bien que, selon certaines estimations, Aladdin contrôlerait plus du double de BlackRock. En 2021, certains estimaient que Aladdin contrôlait au moins 21 mille milliards d’actifs financiers. C’est plus que le PIB des États-Unis d’Amérique !  
https://www.businessinsider.com/what-to-know-about-blackrock-larry-fink-biden-cabinet-facts-2020-12   
https://en.wikipedia.org/wiki/Aladdin_(BlackRock) 

Et ça, très clairement, ça confère à Aladdin un pouvoir et une responsabilité planétaire. Imaginez cela. Il suffit qu’Aladdin modifie 0,005% de ses investissements pour qu’il transforme tout à coup un individu lambda sur terre en un milliardaire ! Vous avez bien entendu : 0,005% des actifs d’Aladdin représente un milliard de dollars. C’est complètement insensé. Une telle modification infime et quasi-invisible d’Aladdin pourrait massivement alimenter la recherche sur la sécurité et l'éthique des algorithmes ; il pourrait aussi booster les entreprises pétrolière. 

J’insiste à nouveau sur l’ampleur du pouvoir d’Aladdin et des intérêts économiques en jeu. Si Aladdin parvient à fructifier ses investissements de 1% par an pour qu’il enrichisse ses clients de 200 milliards de dollars. Plus que le PIB du Qatar ! Sachant cela, ce serait étonnant si l’investissement dans l’optimisation d’Aladdin ne s’élevait pas au moins à des milliards de dollars, et que tous les outils les plus sophistiqués de la recherche actuelle n’étaient pas testés pour améliorer même marginalement les performances prédictives d’Aladdin.

Car oui, si autant d’argent est confié à Aladdin, c’est surtout parce qu’Aladdin semble redoutablement performant dans sa gestion d’actif. En fait, de nombreuses entreprises semblent préférer Aladdin à des équipes d’investisseurs humains, ce qui suggère que Aladdin est en fait déjà très largement non seulement supérieur à un humain, mais même supérieurs aux meilleures équipes d’investisseurs humains. Selon un analyste financier, “il est imbattable”.  
https://lexpansion.lexpress.fr/actualite-economique/enquete-2-3-il-est-imbattable-cet-ordinateur-qui-a-fait-de-blackrock-un-geant-de-la-finance_2161837.html 

Imbattable ou non, quelles que soient les performances effectives d’Aladdin, force est de constater que son pouvoir démesuré représente désormais une menace majeur pour la sécurité mondiale. Aladdin peut plomber des économies entières en cessant certains investissements. Il peut aussi aisément provoquer des courses à l’IA ou à l’armement, en investissant dans ces secteurs ô combien dangereux.

Mais de façon même plus simple, si Aladdin venait tout à coup à changer de stratégies d’investissement, cela provoquerait sans doute des vagues majeures dans l’économie mondiale, mettant ainsi potentiellement en péril l’accès à des biens de base pour des populations entières, avec des risques de guerres civiles, voire de conflits internationaux, voire de guerres mondiales. Sans que l’on s’en rende compte, on a fini par mettre la sécurité mondiale entre les mains de cette IA.  
https://tournesol.app/entities/yt:VELz-MKMWPQ 

Et ça, je trouve ça absolument terrifiant. Il me semble incroyablement urgent de réagir.


## Conclusion

Il y a une tendance à moquer la science-fiction, ce qui n'est pas sans fondement. Cependant, cette moquerie pousse parfois à croire que la réalité est beaucoup plus rassurante que la science-fiction. Cette impression me paraît particulièrement dangereuse, surtout quand elle pousse le public à ne pas mieux s'informer ou à ne pas agir contre la perte de contrôle du grand public, des académiques et des journalistes sur les algorithmes des entreprises et des gouvernements.

Désormais, quand vous penserez à une "IA", j'espère que les exemples qui viendront en tête, ce ne seront pas Terminator, ex Machina et Westworld, ni même DeepBlue, AlphaGo ou thispersondoesnotexist.com. Rien que mentionner ces exemples, c'est en fait donner une vision extrêmement biaisée des IA d'aujourd'hui, un peu comme insister sur les effets secondaires des vaccins induit un biais sur la balance risque-bénéfice des vaccins.

J'espère que, désormais, quand vous penserez IA, vous aurez immédiatement en tête les exemples des armes autonomes, de Tekfog, de Xiaoice, de Pathways et d'Aladdin. Car ces IA sont celles qui comptent vraiment ; ce sont ces IA qui ont acquis un pouvoir dystopiquement disproportionné. Un pouvoir qu'il nous *faut* craindre.

Car, comme le disait 3Blue1Brown à propos du COVID, ce qu'il faut craindre avant tout, c'est peut-être surtout l'absence de crainte #MesTasDeMetas. Or, je crains que, de nos jours, les experts en IA et le grand public pêchent actuellement gravement par absence de crainte, vis-à-vis de technologies pourtant déjà hors de contrôle, ou du moins, hors de tout contre-pouvoir digne de ce nom. Et leur absence de crainte a déjà conduit à un manque désespérant d'investissement en temps et en argent dans la sécurité et l'éthique des algorithmes dont le futur de l'humanité dépend.  
https://tournesol.app/entities/yt:Kas0tIxDvrg 

En particulier, je voudrais insister sur une chose, une fois de plus. La recherche publique sur les performances des algorithmes, en particulier dans le domaine de l'apprentissage automatique, a beaucoup plus de chances d'être exploitée pour améliorer les armes autonomes, Tekfog, Xiaoice, Pathways et Aladin, que pour les applications "AI for good" que les introductions des articles pourraient mentionner, simplement parce que seuls des gouvernements et des entreprises privées milliardaires peuvent aujourd'hui prendre le temps de lire les recherches universitaires et de mettre en œuvre ce qui y est publié. Étant donné l'énorme déséquilibre des moyens dans notre civilisation actuelle, la recherche publique ne fait souvent que donner du pouvoir aux plus puissants. Si vous êtes vous-même un chercheur, un bailleur de fonds ou un futur étudiant, je vous invite vivement à réorienter votre attention vers les questions de sécurité et d'éthique.  
https://tournesol.app/entities/yt:zPTTxsdtI3A 

D'autant que la liste que j'ai donnée dans cette vidéo, aussi effrayante soit-elle déjà, cette liste est très loin d'être exhaustive. En particulier, elle est gravement limitée par l'étendue de mon ignorance ! Pour rappel, je n'ai découvert Aladdin que très récemment. Qui sait quelle autre IA dévastatrice, développée par exemple secrètement par la NSA ou la Chine, est en cours de développement, ou déjà en activité, et risque d'annoncer des lendemains très différents des années 2010, qui paraissent déjà si lointaines ?

Dans ce contexte, il me semble urgent d'agir ; d'agir sur des échelles beaucoup plus grandes que ce qui a été fait jusque là. Ces jours-ci, développer une nouvelle application éthique des IA est très insuffisant ; il nous faut surtout des solutions crédibles pour sécuriser et rendre éthiques Xiaoice, Pathways et Aladdin. Et comme ces IA sont déjà déployées à très, très, très grande échelle, réagir est urgent. Chaque jour compte.  
https://tournesol.app/video/RIGo2ybDA6Q 

Dès lors, qu’est-ce qui peut être fait ? Eh bien, il me semble avant tout urgent de valoriser beaucoup, beaucoup, beaucoup plus l’éthique et la sécurité des algorithmes, ainsi que la paix et le respect des droits humains dans le monde. Et pour cela, il est surtout urgent de mettre en avant les contenus de grande qualité informationnelle, qui sensibilisent efficacement à ces aspects, et qui appellent le grand public et les dirigeants, mais aussi les chercheurs et les journalistes, entre autres, à vraiment agir dans cette direction. Il y a une guerre de l’information, en faveur de l’éthique et la sécurité, et contre la performance et la spectacularité, qu’il est urgent de gagner.  
https://tournesol.app/entities/yt:ecqtrDTfDm4

Et à ce jour, vous me voyez venir, le meilleur outil pour mener cette guerre, c’est, il me semble, la plateforme Tournesol, qui vise à identifier collaborativement les contenus de top qualité. En particulier, le grand défi à l’heure actuelle est de crédibiliser cette plateforme, en lui fournissant un grand nombre de données. On espère aussi que ces données motiveront les chercheurs à s’intéresser à cette plateforme, et pourront finir par devenir un outil pour non seulement identifier les contenus informationnels d’utilité publique, mais aussi pour auditer la qualité des recommandations des algorithmes d’aujourd’hui, voire pour imposer des régulations pragmatiques et efficaces sur les IA les plus puissantes d’aujourd’hui.

Certes, je ne vous le cache pas, il y a un long chemin à parcourir si on veut un jour contester les armes autonomes, Tekfog, Xiaoice, Pathways et Aladdin. Mais comme le dit le proverbe, « le plus long des voyages commence par un premier pas ». Je vous supplie de nous aider à effectuer ce voyage, en vous connectant à Tournesol, et en soumettant vos premières comparaisons. 

Pour cela, vous pouvez suivre le lien description, et comparer cette vidéo avec une autre vidéo que vous avez vu récemment. Vous pouvez aussi profiter des recommandations de Tournesol en installant l'extension Chrome ou Firefox et en suivant les Tournesols Bot sur Twitter. Et si vous trouvez ce combat important et que vous pouvez vous le permettre, vous pouvez nous aider financièrement, via uTip ou Paypal. Vous pouvez aussi venir nous aider à développer la platforme en participant à l'écriture du code Open Source sur Github, ou nous rejoindre sur Discord si vous avez d'autres compétences qui pourraient nous être utiles, comme par exemple nous aider à chercher des financements.




