# La distraction stratégique #coolwashing

## Introduction

Les modèles de langage ne sont que des "machines à compléter des phrases".
Et ça c'est cool !
Pourquoi pensez-vous qu'un outil pour compléter/prédire du texte 
dans les mains du grand public peut conduire à de mauvaises conséquences ?
https://twitter.com/JacksonKernion/status/1446620267300601861

Telles sont des interrogations de Jackson Kernion, 
docteur en philosophie qui travaille maintenant chez Anthropic,
une organisation formée de beaucoup d'anciens membres d'OpenAI,
qui vise à construire des algorithmes "fiables, interprétables et dirigeables".

Et j'ai tellement envie de rétorquer "ok, mais dirigeables par qui ?"
à ces gens sensés bosser sur la sécurité des algorithmes,
mais dont la réflexion philosophique n'inclut même pas 
l'existence pourtant largement avérée de la guerre mondiale de l'information.

Mais si j'ai sélectionné un tweet de ce chercheur pour introduire cette vidéo,
ce n'est pas pour rabâcher mes critiques d'OpenAI, d'Anthropic 
et de toute la sphère "AI Safety" du mouvement Altruisme Efficace,
qui a en fait énormément contribué à la dangerosité des algorithmes,
et très peu apporté à mon sens à la sécurité de ces algorithmes.

Non, si j'en parle, c'est beaucoup plus parce que
ce tweet me semble parfaitement illustrer les ravages de la distraction stratégique
développée par l'industrie des technologies
sur l'inattention du grand public, des scientifiques, 
des journalistes, des régulateurs et des politiciens,
vis-à-vis des catastrophes et des risques existentiels 
que soulèvent déjà les algorithmes d'aujourd'hui.

En particulier, à l'instar des industries du tabac, du sucre ou de l'automobile,
les entreprises du numérique investissent massivement dans ce que je vais appeler le #coolwashing,
pour normaliser la consommation abusive de produits dangereux,
et pour freiner les critiques, les alternatives et les initiatives de régulation.

Aujourd'hui, je vais essayer de vous convaincre que 
ce #coolwashing est une menace civilisationnelle
qu'il est urgent de se combattre,
en exigeant de nous-mêmes, de nos amis et de nos collègues
de ne pas tomber dans l'émerveillement démesuré pour ce qui paraît "cool".

À l'inverse, il paraît crucial de se méfier beaucoup plus de ce que cette apparence "cool" cache,
et de valoriser davantage ce qui semble beaucoup plus clairement bénéfique à nos sociétés.
Et comme toujours dans cette série de vidéo,
je finirai en parlant de la solution que nous proposons, à savoir la plateforme Tournesol,
pour contrer la distraction stratégique mise en place 
par les multinationales et les puissances nationales à travers le monde.


## Les investissements massifs de Big Tech

Il y a quelques semaines, j'ai eu l'honneur d'être invité à FLAIM,
un événement académique organisé par Meta à l'Institut Henri Poincaré.
Pour ceux qui n'ont pas suivi, Meta est le nouveau nom de Facebook.
J'y ai parlé de la cybersécurité du machine learning,
et en particulier de l'importance des théorèmes mathématiques
pour évaluer la vulnérabilité des algorithmes développés en apprenant de données d'utilisateurs.

Mais le thème de la conférence était assez différent.
Il s'agissait davantage de réunir ceux qui appliquent le machine learning aux mathématiques.
Et force est de constater que les algorithmes modernes sont capables de prouesses spectaculaires,
souvent très largement surhumaines,
notamment grâce à la formalisation algorithmique des preuves mathématiques et de leur vérification.

Et très clairement, à cette conférence, Big Tech était surreprésenté,
qu'il s'agisse de Facebook, Google ou autres OpenAI,
par opposition aux académiques qui n'ont généralement pas accès
à suffisamment de supercalculateurs pour effectuer les calculs monstrueux
nécessaires pour concevoir des algorithmes surhumains en mathématiques.
https://www.ihp.fr/en/events/conference-flaim-formal-languages-ai-and-mathematics

Qui plus est, à côté des dizaines de millions de dollars nécessaires 
pour payer la facture électrique des supercalculateurs qui font des mathématiques,
les salaires cumulés des chercheurs présents se chiffraient eux aussi certainement en millions,
voire en dizaines de millions.
Mais donc, pourquoi ? Pourquoi Big Tech investit autant dans des domaines qui, clairement,
ne sont pas les plus utiles pour leurs produits, et donc a priori pour leurs revenus ?

Pourquoi Facebook, pourtant dans le dur financièrement, 
investit autant dans le machine learning pour les mathématiques ?
Pourquoi Google a-t-il racheté DeepMind, 
et les félicite de faire des algorithmes 
pour bien jouer aux échecs, au go et aux jeux vidéos,
ou pour résoudre le problème du repliement de protéine ?

Et pourquoi OpenAI investit autant pour produire des IA "artistiques", 
capables de générer des images spectaculaires
ou de converser de manière bluffante ?
Qu'est-ce qui justifie, d'un point de vue économique, le salaire de ces chercheurs ?

Telles sont les questions que je n'ai cessé de poser aux participants à la conférence.
Et, en gros, personne ne s'était même posé la question.
Tous étaient trop distraits par la spectacularité des algorithmes développés.
Et bien, il me semble que c'était justement ça, l'objectif économique de cette conférence.
Il s'agissait de distraire les chercheurs des enjeux économiques et géopolitiques
des algorithmes de machine learning,
et de donner l'impression que l'IA, c'est cool !

(alors que nombres de leurs collègues, notamment Frances Haugen et Sophie Zhang,
appellent désespérément à "ne pas fermer les yeux"
sur les atrocités auxquels les algorithmes de Meta ont largement contribué,
comme le génocide de Rohingyas et du Tigray, le chaos informationnel du COVID,
voire les émeutes du Capitol et la tentative de coup d'état par l'extrême droite en Allemagne...)

Le #coolwashing a terriblement bien marché.


## Les investissements massifs de Big Tech


## L'inattention tue

COVID

Tabac, sucre

Changement climatique

Aide humanitaire

## La modération est une distraction stratégique

Retirer le mal n'est pas la solution.

## Tournesol et le rectangle jaune

Que mettre dans ce rectangle jaune ?



