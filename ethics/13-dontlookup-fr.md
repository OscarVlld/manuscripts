# La pénurie d’attention #DontLookUp
https://tournesol.app/entities/yt:lqfNjyuMKeY

https://www.youtube.com/watch?v=6F3qTi-McZI  
“Please don’t say 100%”.

Comme des centaines de millions d’humains sur terre, j’ai regardé le film récent “Don’t Look Up”, et je l’ai trouvé si intéressant sur certains aspects si importants, que je me suis dit que ça valait la peine que j’arrête mes activités habituelles, et que je vous propose une vidéo “un peu spéciale”, comme diraient les YouTubeurs.

En particulier, j’aimerais insister sur quatre aspects particulièrement intéressants du film à mes yeux ; et comme vous allez le voir, je vais fournir à la fois des éloges et des critiques…  Bon j’ajoute par ailleurs que je ne compte pas du tout parler de la forme, n’étant absolument pas expert en critique cinématographique. Ce qui m’intéresse, ce sont les problèmes de société, et en particulier de l’éthique de l’information, que le film soulève.

Attention, du coup, il va y avoir des spoilers.

## Crise de l’information

Selon le réalisateur et les principaux acteurs, à l’origine, Don’t Look Up se voulait être une analogie avec la crise environnementale. Cependant, de leur propre aveux, suite à la pandémie du COVID-19 et aux mouvements Black Lives Matter, le film a pris une tournure plus générale, si bien que la problématique environnementale me semble être devenue très largement secondaire.

En fait, le problème plus fondamental que me semble soulever le film, c’est le problème de la production, de la diffusion et de la consommation de l’information. Et c’est pour ça que le film m’a beaucoup intéressé. Il met le doigt sur ce qui me semble être le problème le plus important du monde moderne, notamment parce qu’il est au cœur de toutes les autres causes, à savoir la manière dont l’information est traitée et communiquée à l’échelle planétaire.

D’ailleurs, à ce sujet, je vais me permettre de lire cet extrait du 1er chapitre de notre livre Le Fabuleux Chantier, co-écrit avec El Mahdi El Mhamdi :

“La priorité de nombreux mouvements philanthropiques est la sensibilisation d’un grand public ou d’un public cible à leurs causes. Pensez à la pauvreté dans le monde, aux inégalités de genre et de races, ou encore au changement climatique. Dans tous ces cas, et dans de nombreux autres, le goulot d’étranglement de l’altruisme est bien souvent la diffusion de l’information de qualité. Voilà qui est précisément le cœur de métier des IA. Une IA bénéfique dans le traitement des informations serait alors un allié formidable pour tous ces mouvements caritatifs.”

Or malheureusement, à l’heure actuelle, les algorithmes, ces outils à traiter et à diffuser l’information à l’échelle planétaire, ne sont absolument pas conçus pour être bénéfique, et pour être des alliés des causes importantes. Ces algorithmes pourraient amplifier massivement la mobilisation contre les agressions violentes de puissances autoritaires, et le courage héroïque de ceux qui, au péril de leurs vies, appellent à la paix. Malheureusement, au contraire, ces algorithmes sont aujourd’hui conçus avec très peu de mesures de sécurité, ce qui a permis à de nombreuses campagnes de désinformation, venant d’entreprises privées et de gouvernements souvent autoritaires, de manipuler les algorithmes pour noyer les informations qui les compromettent. 

Pire encore, les révélations des Facebook Files montrent que les dirigeants de Facebook se sont régulièrement rendus complices de telles manoeuvres, en blanchissant des dictateurs, en facilitant le trafic d’humains ou encore en amplifiant massivement les appels à la haine, voire au génocide.

Bien sûr, les algorithmes ne sont pas les seuls à amplifier la crise de l’information. De nos jours, une poignée de dictateurs ou de milliardaires surpuissants ont monopolisé les médias classiques d’information, que ce soit en Chine ou en Russie, ou en France et dans le monde anglophone. Et même quand les médias ont une certaine indépendance, le capitalisme de l’information les pousse systématiquement vers des contenus plus aguicheurs et plus populistes, ce qui rend souvent impossible la communication d’informations importantes, car moins attirantes pour le grand public.

[EXTRAIT : scène où les présentateurs disent qu'il faut parler avec légèreté]

D’ailleurs, c’est un peu ironique, je trouve, de faire des vidéos sur Don’t Look Up en discutant d’astronomie… car ça fait justement du sujet de la crise informationnelle une mute news ! De façon générale, il me semble important que tout producteur de contenu prenne conscience du coût d’opportunité induit par ses propres communications ; à chaque fois qu’on attire l’attention du public sur un sujet, on détourne aussi inévitablement son attention d’autres sujets, potentiellement beaucoup plus importants ; on contribue à faire des sujets importants des mute news. 

Bien sûr, il ne s’agit pas de constamment rabâcher des informations importantes uniquement, mais typiquement, expliquer le fonctionnement des algorithmes d'apprentissage modernes sans jamais mentionner leurs effets secondaires majeurs dans le monde moderne, c’est justement compliquer la tâche de ceux qui cherchent à souligner l’ampleur préoccupante de ces effets secondaires.

Cette technique de détournement de l’attention du grand public semble d’ailleurs la technique principale de désinformation du gouvernement chinois.

## La gestion des probabilités

Alors, il y a quand même une scène de Don’t Look Up qui m’a beaucoup dérangé. Comme vous l’aurez peut-être deviné, il s’agit de la scène où les deux scientifiques experiment leur degré de certitude sur la catastrophe à venir.  
https://www.youtube.com/watch?v=6F3qTi-McZI 

Vous devinez ce qui me dérange ? La scène donne l’impression qu’il faut être sûr qu’un événement catastrophique arrivera pour s’en préoccuper. C’est malheureusement une impression dégagée tout au long du film. 

Et alors, en un sens, c’est une expérience de pensée intéressante et déjà très préoccupante de se rendre compte que même un événement catastrophique quasi certain ne semble pas suffisant pour mobiliser la population et les dirigeants des pays démocratiques. Mais c’est en fait d’autant plus désespérant de se rendre compte que, même un risque de 70% ne semble pas suffisant pour alarmer même des scientifiques !

D’ailleurs, même dans la présentation des risques environnementaux, il me semble y avoir un biais récurrent vers ce dont on est sûr ; au détriment potentiellement des scénarios futurs moins probables, mais beaucoup plus catastrophiques. 

En fait, j’aurais trouvé l’expérience de pensée plus fascinante encore, si la comète du film n’avait qu’une probabilité de 10% de s’écraser sur la planète, à cause d’imprécisions sur les mesures de trajectoire de la comète, qui pourrait ne faire qu’effleurer la planète. Imaginez comment cette probabilité aurait été maltraitée par les dirigeants, les médias, le grand public, et même de nombreux scientifiques, qui voulant se tirer la couverture, pourraient prétendre que le 10% est mal calculé, ou que, eux, sont des scientifiques qui ne traitent que de faits établis, et pas de considérations aussi subjectives que des estimations probabilistes.

Mais surtout, l’expérience de pensée aurait tout à coup paru beaucoup plus réaliste. Souvenez-vous par exemple des premières heures du COVID-19. Même s’ils ne le quantifiaient pas ainsi, certains scientifiques appelaient déjà à se préparer à un risque de pandémie, même lorsque cette pandémie n’était pas du tout garantie de mettre en danger toute la planète ; à l’instar d’Ebola, du MERS ou de la grippe A H1N1.

Et qu’en est-il des risques aujourd’hui pour les catastrophes futures ? Quelle probabilité assignez-vous par exemple à une 3e Guerre Mondiale dans les 5 années à venir ? Ou pire encore, quelle probabilité assignez-vous à une 3e Guerre Mondiale durant laquelle des technologies de drônes tueurs autonomes seront massivement déployées par des superpuissances comme les États-Unis ou la Chine ?

Personnellement, au vu des événements récents et de la course actuelle à l’armement dans les superpuissances à travers le monde, j’ai bien peur de ne pas pouvoir assigner une probabilité inférieure à 10% à une telle catastrophe, qui mettrait en péril des milliards de vies humaines. Mais d’un autre côté, clairement aussi, un tel événement n’a rien de certain. En tout cas, je ne lui assigne absolument pas une probabilité de 100%.

En fait, il me semble que, comme le propose l’Assistant de la Présidente de Don’t Look Up, on peut considérer que le risque d’une 3e Guerre Mondiale désastreuse dans les 5 années à venir peut tout à fait être qualifiée “d’événement potentiellement catastrophique”. Mais est-ce une raison pour autant qu’il faut l’ignorer ? Est-ce une raison de se "rassoir et faire le point" ? 

Si une comète n'avait que 10% de chances de détruire toute l'humanité dans 6 mois, ne faudrait-il pas investir des centaines de milliards de dollars pour être quasiment garantis de pouvoir détourner la comète, au cas où ? De la même façon, s'il y a 10% de chances d'une guerre nucléaire ou d'une guerre de drones autonomes dans les 5 années à venir, ne faudrait-il pas investir des milliards de dollars pour combattre la désinformation et les appels à la haine, qui catalysent ces risques ? Ou au moins exiger des réseaux sociaux qu'ils investissent de telles sommes dans la sécurité et l'éthique de leurs algorithmes, plutôt que, disons, dans un métavers dont personne ne veut ?

## Peer review

Un épisode particulièrement intéressant de Don’t Look Up, et attention je vais pas mal spoiler le film, c’est le moment où l’entreprise BASH prétend disposer des meilleurs scientifiques, qui sont garantis de pouvoir miner la comète tout en la déviant et en protégeant la terre. Un prix Nobel prend alors la parole pour expliquer très superficiellement le plan de l’entreprise.

EXTRAIT

Cependant, l’entreprise BASH est rapidement critiquée par de plus en plus de scientifiques, frustrés de ne pas pouvoir auditer les plans de l’entreprise, car ceux-ci ne sont pas rendus publics. Voilà qui contraste fortement avec la tradition de peer review du monde académique, où une conclusion scientifique doit être expliquée et justifiée dans un article scientifique, et acceptée par les pairs scientifiques, pour être considérée valide. Clairement, on a envie de dire que quand l’enjeu est le futur de l’humanité, ce minimum de transparence et d’auditabilité devrait être exigé, ce qui rend l’opacité de l’entreprise BASH extrêmement frustrante.

Cette scène m’a énormément interpelé, car c’est exactement ce que l’on observe dans le monde de l’intelligence artificielle. Une poignée de mastodontes, à savoir Google, Apple, Facebook, Amazon et Microsoft, mais aussi Tiktok, WeChat, voire des gouvernements autoritaires comme les autorités Russes et Chinoises, ont un contrôle disproportionné du flux de l’information et de la mésinformation à travers le monde, et prétendent maîtriser leurs technologies opaques en recrutant des scientifiques très médaillés, comme par exemple des lauréats du prix Turing.

Sauf que, très clairement, même si j’avais confiance en les intentions de ces groupes — ce qui n’est absolument pas le cas, sachant en particulier que Google a licencié son équipe d’éthique et sachant les Facebook Files révélées par la lanceuse d’alerte de Facebook Frances Haugen — mais même si je croyais que les scientifiques de ces entités étaient aux commandes et étaient bien intentionnés, je comprends beaucoup trop bien les vulnérabilités béantes du machine learning pour n’avoir aucunement confiance en la capacité de ces scientifiques de concevoir des algorithmes sécurisés. 

Après tout, même des algorithmes beaucoup plus simples, comme iOS ou Android, ont des bugs que les logiciels espions comme Pegasus ou DarkMatter exploitent pour surveiller des milliers, voire peut-être des millions ou des milliards de téléphones. En fait, tout expert en sécurité informatique dira que seuls des algorithmes Open Source comme Linux, dont les vulnérabilités ont été cherchées et corrigées par une énorme communauté de développeurs pendant des décennies, sont vraiment dignes de confiance.

Or, je ne peux insister sur l’importance de ces algorithmes de recommandation pour le futur de l’humanité. En amplifiant la haine et la mésinformation, en se laissant hacker par les campagnes de désinformation, et en noyant les informations vraiment importantes dans un énorme brouhaha informationnel, ces algorithmes sont en train de sacrifier l’humanité, en nous empêchant de nous préparer à des catastrophes monumentales, et en nous montant les uns contre les autres, préparant ainsi le terrain pour des guerres destructives avec de nouvelles armes surpuissantes.

Plus que jamais, il est critique de nous méfier beaucoup plus des algorithmes qui gouvernent le flux de l’information sur Internet, d’exiger leur transparence, et d’investir massivement dans leur audit. Le futur de l’humanité en dépend.

## S’indigner… et passer à autre chose

Mais s’il y a un aspect qui ne cesse d’être illustré par Don’t Look Up, et qui me frustre particulièrement en pratique, c’est l’incroyable difficulté qu’il y a à impliquer les gens, et à aller au-delà de la simple indignation. Il est tellement facile de poster un message de soutien ou d’indignation ; mais il est tellement rare que l’on aille plus loin, et qu’on investisse son temps libre, ses économies, voire sa propre carrière, pour résoudre les problèmes qui menacent pourtant toute l’humanité.

[EXTRAIT de “The most dangerous man in America”]

Je ne peux que vous encourager à ne pas passer à autre chose, surtout quand il s’agit de la crise de l’information. Car la crise de l’information, c’est avant tout une guerre de l’information, qu’il faut mener en permanence pour ne pas céder de terrain aux campagnes de désinformation qui veulent remplacer l’information de qualité par de la mésinformation, ou par des informations distrayantes. En particulier, faites attention à vos activités sur les réseaux sociaux, et prenez régulièrement le soin de prioriser l’information importante ; ou au moins à régulièrement encourager ceux qui le font.

Mais si vous voulez vraiment combattre la mésinformation et la haine efficacement, je vous invite surtout à beaucoup mieux vous informer sur la crise de l’information, pour comprendre les mécanismes de désinformation, et les solutions les plus prometteuses pour diffuser au mieux l’information qui importe. À titre personnel, en tout cas, cela fait au moins 5 ans que j’étudie ces sujets au quotidien, et en plus d'essayer de produire des contenus de qualité sur des sujets importants, j’en suis surtout venu à la conclusion que la priorisation de l’information par les médias et les algorithmes était vraiment la clé de cette bataille de l’information — et Tournesol est né pour corriger ce problème.

D'ailleurs, depuis le début de Tournesol, beaucoup de gens m’ont envoyé des messages de félicitations et d’encouragement. Beaucoup ont ouvert un compte, et noté quelques vidéos. Beaucoup ont rejoint le Discord, et posé des questions. Certains ont même contribué à la réflexion autour du projet, voire à l’écriture du code. Mais la plupart ont fini par quitter le projet, avant de vraiment y investir une partie importante de leur temps, de leur argent ou de leur carrière.

Je vous supplie de ne pas en faire de même. Restez régulièrement engagé dans l'infoguerre contre la mésinformation et les appels à la haine. Et pour cela, il y a une chose très simple que vous pouvez faire, à savoir créer un compte sur Tournesol, et régulièrement comparer des vidéos YouTube sur notre plateforme.

Notre objectif est en particulier d’atteindre un million de comparaisons fournies par notre contributeur d’ici la fin de l’année 2022. En plus d’être un chiffre symbolique important, ceci nous permettra d’établir une base de données solides pour accélérer la recherche sur des algorithmes éthiques et sécurisés, et pour ainsi convaincre la communauté des ingénieurs et des chercheurs de s’intéresser à ce problème ô combien important. Et si Tournesol devient un jour convainquant, peut-être pourra-t-on enfin espérer voir des investissements de l'ordre du milliard de dollars dans la priorisation collaborative des informations fiables, importantes et bienveillantes.

La désinformation et la haine sont en train de dominer la guerre de l'information, et menacent la sécurité mondiale. Chaque contribution que vous ferez à Tournesol sera une riposte. Pour faire enfin triompher l'information de qualité et la bienveillance envers son prochain, nous avons désespérément besoin de ces contributions.

J'espère que, contrairement au grand public décrit par Don't Look Up, je pourrai compter sur vous.



